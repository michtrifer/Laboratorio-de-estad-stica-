{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbc04fc6",
   "metadata": {},
   "source": [
    "# Examen 1 (Correciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af677434",
   "metadata": {},
   "source": [
    "## Teoría"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d72b0",
   "metadata": {},
   "source": [
    "- 1. **¿Qué es un pipeline?** \n",
    "\n",
    "Un pipeline es es una serie de pasos que se ejecutan uno tras otro, donde la salida de una fase se convierte en la entrada de la siguiente. Su propósito es mover y transformar datos ordenadamente.\n",
    "\n",
    "- 2. **¿Cuál es el propósito de realizar regresiones? Explica las ventajas y desventajas de los dos planteamientos vistos en clase.**\n",
    "\n",
    "La regresión sirve para analizar la relación entre variables y predecir un valor numérico (y) a partir de otro (X).\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "-Es fácil interpretar.\n",
    "\n",
    "-Permite predecir valores futuros.\n",
    "\n",
    "-Ayuda a identificar qué variables influyen más en el resultado.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "-Es sensible a valores atípicos (outliers).\n",
    "\n",
    "-Puede haber sobreajuste o problemas de multicolinealidad.\n",
    "\n",
    "\n",
    "- 3. **¿En qué consiste el proceso de escalamiento de factores?**\n",
    "\n",
    "Escalar significa poner todas las variables en la misma escala, normalmente entre 0 y 1 o con media 0 y desviación 1. Esto evita que variables con números grandes dominen el modelo.\n",
    "\n",
    "- 4. **Explica el propósito de penalizar factores en una regresión.**\n",
    "\n",
    "El propósito de penalizar factores es reducir la importancia de variables poco útiles o irrelevantes. Esto evita que las Betas crezcan demasiado y ayuda a que las predicciones sean más precisas.\n",
    "\n",
    "- 5. **¿Cuál es la relación entre escalamiento y penalización?**\n",
    "\n",
    "Para que la penalización funcione bien, las variables deben estar escaladas. Si no, las variables con números más grandes recibirían un castigo más fuerte solo por su tamaño, no por su importancia real.\n",
    "\n",
    "- 6. **Explica el concepto de una prueba de hipótesis.**\n",
    "\n",
    "Una prueba de hipótesis es un método estadístico que se usa para decidir, con base en datos, si una afirmación es probablemente cierta o no. Se plantea una hipótesis inicial (H₀) y una alternativa (H₁), y a partir de una muestra se evalúa si hay suficiente evidencia para rechazar H₀.\n",
    "\n",
    "- 7. **Explica la interpretación de un p-value de una prueba de hipótesis que compara contra una media µ.**\n",
    "\n",
    "El p-value nos dice la probabilidad de ver los datos que tenemos si la hipótesis que estamos probando es cierta.\n",
    "\n",
    "Si el p-value es pequeño (ej. < 0.05), los datos no concuerdan con la hipótesis, y podemos rechazarla.\n",
    "Si el p-value es grande, no hay evidencia suficiente para rechazar la hipótesis.\n",
    "\n",
    "- 8. **Describe el propósito de realizar cross-validation.**\n",
    "\n",
    "Cross-validation sirve para probar qué tan bien funciona un modelo en datos nuevos. Se divide el conjunto de datos en partes, se entrena en algunas y se prueba en otras, y así se obtiene una medida más confiable del rendimiento.\n",
    "\n",
    "- 9. **Describe los pasos que seguirías al hacer un análisis exploratorio de datos. Justifica cada paso.**\n",
    "\n",
    "-Revisar los datos: entender qué columnas y tipos de datos hay.\n",
    "\n",
    "-Investigar sobre el tema del dataset para poder interpretar los resultados.\n",
    "\n",
    "-Limpiar los datos: quitar valores faltantes (Nans) o duplicados.\n",
    "\n",
    "-Explorar estadísticas básicas: medias, medianas, desviaciones para conocer la distribución de cada variable.\n",
    "\n",
    "-Visualizar los datos: usar gráficos para ver patrones, relaciones o valores atípicos.\n",
    "\n",
    "\n",
    "- 10. **¿Qué es el teorema del límite central?**\n",
    "\n",
    "Es un principio que dice que la media de muchas muestras aleatorias de una población tiende a tener una distribución normal, sin importar la distribución original de los datos. Esto permite usar técnicas estadísticas basadas en la normalidad sin importar la forma original de la población."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1bdf16",
   "metadata": {},
   "source": [
    "## Práctica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c80f095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24cec4e",
   "metadata": {},
   "source": [
    "### 1. Encontrar la parábola que pasa exactamente por los puntos (1, 2), (1,1) y (3,2). Utiliza la librería sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "abafcde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercepto 4.9999999999999964 Coeficientes [-4.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Puntos dados\n",
    "X = np.array([[1],[2],[3]])\n",
    "y = np.array([2,1,2])\n",
    "\n",
    "X2 = np.hstack([X, X**2]) \n",
    "\n",
    "lr2=LinearRegression() \n",
    "lr2.fit(X2,y) \n",
    "\n",
    "y_pred2 = lr2.predict(X2) \n",
    "\n",
    "print(\"Intercepto\",lr2.intercept_,\"Coeficientes\",lr2.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bfff022e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michelle Trigo\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n",
      "C:\\Users\\Michelle Trigo\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1794: RuntimeWarning: divide by zero encountered in divide\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "C:\\Users\\Michelle Trigo\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1794: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "C:\\Users\\Michelle Trigo\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1716: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 29 Sep 2025</td> <th>  Prob (F-statistic):</th>  <td>   nan</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:36:32</td>     <th>  Log-Likelihood:    </th> <td>  99.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>     3</td>      <th>  AIC:               </th> <td>  -192.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     0</td>      <th>  BIC:               </th> <td>  -195.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    5.0000</td> <td>      inf</td> <td>        0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -4.0000</td> <td>      inf</td> <td>       -0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    1.0000</td> <td>      inf</td> <td>        0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>   nan</td> <th>  Durbin-Watson:     </th> <td>   0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td>   nan</td> <th>  Jarque-Bera (JB):  </th> <td>   0.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.707</td> <th>  Prob(JB):          </th> <td>   0.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.500</td> <th>  Cond. No.          </th> <td>    70.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &       nan   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &       nan   \\\\\n",
       "\\textbf{Date:}             & Mon, 29 Sep 2025 & \\textbf{  Prob (F-statistic):} &      nan    \\\\\n",
       "\\textbf{Time:}             &     21:36:32     & \\textbf{  Log-Likelihood:    } &    99.193   \\\\\n",
       "\\textbf{No. Observations:} &           3      & \\textbf{  AIC:               } &    -192.4   \\\\\n",
       "\\textbf{Df Residuals:}     &           0      & \\textbf{  BIC:               } &    -195.1   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       5.0000  &          inf     &         0  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{x1}    &      -4.0000  &          inf     &        -0  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{x2}    &       1.0000  &          inf     &         0  &           nan        &          nan    &          nan     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &    nan & \\textbf{  Durbin-Watson:     } &    0.059  \\\\\n",
       "\\textbf{Prob(Omnibus):} &    nan & \\textbf{  Jarque-Bera (JB):  } &    0.531  \\\\\n",
       "\\textbf{Skew:}          & -0.707 & \\textbf{  Prob(JB):          } &    0.767  \\\\\n",
       "\\textbf{Kurtosis:}      &  1.500 & \\textbf{  Cond. No.          } &     70.9  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                    nan\n",
       "Method:                 Least Squares   F-statistic:                       nan\n",
       "Date:                Mon, 29 Sep 2025   Prob (F-statistic):                nan\n",
       "Time:                        21:36:32   Log-Likelihood:                 99.193\n",
       "No. Observations:                   3   AIC:                            -192.4\n",
       "Df Residuals:                       0   BIC:                            -195.1\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          5.0000        inf          0        nan         nan         nan\n",
       "x1            -4.0000        inf         -0        nan         nan         nan\n",
       "x2             1.0000        inf          0        nan         nan         nan\n",
       "==============================================================================\n",
       "Omnibus:                          nan   Durbin-Watson:                   0.059\n",
       "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.531\n",
       "Skew:                          -0.707   Prob(JB):                        0.767\n",
       "Kurtosis:                       1.500   Cond. No.                         70.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ols=sm.add_constant(X2)\n",
    "ols = sm.OLS(y, X_ols)\n",
    "results = ols.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bdc7d1",
   "metadata": {},
   "source": [
    "#### Ecuación de la parábola\n",
    "\n",
    "La ecuación de la parábola es:\n",
    "$y = x^2 - 4x + 5$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19994625",
   "metadata": {},
   "source": [
    "### 2. Dado el siguiente código, explica paso por paso qué es lo que se está haciendo y el objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35a7b1",
   "metadata": {},
   "source": [
    "El código carga datos de viviendas en California, separa las características (X) y la variable objetivo (y), normaliza las columnas con StandardScaler y entrena un modelo de regresión lineal dentro de un pipeline. Después aplica un K-Folds Validation, con 10 folds, es decir, divide el dataset en 10 partes iguales, el modelo se entrena 9 veces con 9 partes y se prueba con la parte que quedó fuera. Esto se repite 10 veces, cambiando cada vez la parte que se deja fuera. Al final se tienen 10 resultados de error (MSE), que se promedian. El objetivo es  ver qué tan bien la regresión lineal predice los precios de las casas.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d55bbc9",
   "metadata": {},
   "source": [
    "### 3. Entrega un modelo para predecir el \"IMDB_Rating\" de una película dados los factores que consideres adecuados.\n",
    "\n",
    "- Utiliza sklearn para el modelo.\n",
    "\n",
    "- Utiliza escalamiento para los factores numéricos, y transformaciones para los factores cualitativos.\n",
    "\n",
    "- Calcula los p-values de los factores utilizados. Interpreta tus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dd260051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Series_Title</th>\n",
       "      <th>Released_Year</th>\n",
       "      <th>Certificate</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>IMDB_Rating</th>\n",
       "      <th>Meta_score</th>\n",
       "      <th>Director</th>\n",
       "      <th>Gross</th>\n",
       "      <th>Drama</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Family</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>War</th>\n",
       "      <th>Music</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Sport</th>\n",
       "      <th>History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>A</td>\n",
       "      <td>142 min</td>\n",
       "      <td>9.3000</td>\n",
       "      <td>80.0000</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>28,341,469</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>A</td>\n",
       "      <td>175 min</td>\n",
       "      <td>9.2000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>134,966,411</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>UA</td>\n",
       "      <td>152 min</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>84.0000</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>534,858,444</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>A</td>\n",
       "      <td>202 min</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>57,300,000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>U</td>\n",
       "      <td>96 min</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>96.0000</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>4,360,000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              Series_Title Released_Year Certificate  Runtime  \\\n",
       "0           0  The Shawshank Redemption          1994           A  142 min   \n",
       "1           1             The Godfather          1972           A  175 min   \n",
       "2           2           The Dark Knight          2008          UA  152 min   \n",
       "3           3    The Godfather: Part II          1974           A  202 min   \n",
       "4           4              12 Angry Men          1957           U   96 min   \n",
       "\n",
       "   IMDB_Rating  Meta_score              Director        Gross  Drama  ...  \\\n",
       "0       9.3000     80.0000        Frank Darabont   28,341,469      1  ...   \n",
       "1       9.2000    100.0000  Francis Ford Coppola  134,966,411      1  ...   \n",
       "2       9.0000     84.0000     Christopher Nolan  534,858,444      1  ...   \n",
       "3       9.0000     90.0000  Francis Ford Coppola   57,300,000      1  ...   \n",
       "4       9.0000     96.0000          Sidney Lumet    4,360,000      1  ...   \n",
       "\n",
       "   Fantasy  Family  Thriller  Romance  Sci-Fi  War  Music  Musical  Sport  \\\n",
       "0        0       0         0        0       0    0      0        0      0   \n",
       "1        0       0         0        0       0    0      0        0      0   \n",
       "2        0       0         0        0       0    0      0        0      0   \n",
       "3        0       0         0        0       0    0      0        0      0   \n",
       "4        0       0         0        0       0    0      0        0      0   \n",
       "\n",
       "   History  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"imdb_top1000_lae.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6c7c7bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dbfd014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 714 entries, 0 to 997\n",
      "Data columns (total 30 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Unnamed: 0     714 non-null    int64  \n",
      " 1   Series_Title   714 non-null    object \n",
      " 2   Released_Year  714 non-null    object \n",
      " 3   Certificate    714 non-null    object \n",
      " 4   Runtime        714 non-null    object \n",
      " 5   IMDB_Rating    714 non-null    float64\n",
      " 6   Meta_score     714 non-null    float64\n",
      " 7   Director       714 non-null    object \n",
      " 8   Gross          714 non-null    object \n",
      " 9   Drama          714 non-null    int64  \n",
      " 10  Crime          714 non-null    int64  \n",
      " 11  Action         714 non-null    int64  \n",
      " 12  Biography      714 non-null    int64  \n",
      " 13  Western        714 non-null    int64  \n",
      " 14  Comedy         714 non-null    int64  \n",
      " 15  Adventure      714 non-null    int64  \n",
      " 16  Animation      714 non-null    int64  \n",
      " 17  Horror         714 non-null    int64  \n",
      " 18  Mystery        714 non-null    int64  \n",
      " 19  Film-Noir      714 non-null    int64  \n",
      " 20  Fantasy        714 non-null    int64  \n",
      " 21  Family         714 non-null    int64  \n",
      " 22  Thriller       714 non-null    int64  \n",
      " 23  Romance        714 non-null    int64  \n",
      " 24  Sci-Fi         714 non-null    int64  \n",
      " 25  War            714 non-null    int64  \n",
      " 26  Music          714 non-null    int64  \n",
      " 27  Musical        714 non-null    int64  \n",
      " 28  Sport          714 non-null    int64  \n",
      " 29  History        714 non-null    int64  \n",
      "dtypes: float64(2), int64(22), object(6)\n",
      "memory usage: 172.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "40ab911e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>IMDB_Rating</th>\n",
       "      <th>Meta_score</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Action</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Western</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Family</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>War</th>\n",
       "      <th>Music</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Sport</th>\n",
       "      <th>History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "      <td>714.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>518.5728</td>\n",
       "      <td>7.9371</td>\n",
       "      <td>77.1583</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.1989</td>\n",
       "      <td>0.1961</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.2283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0770</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>295.8481</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>12.4011</td>\n",
       "      <td>0.4585</td>\n",
       "      <td>0.3994</td>\n",
       "      <td>0.3973</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>0.4182</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2668</td>\n",
       "      <td>0.2381</td>\n",
       "      <td>0.3458</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>0.2690</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.2161</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.2246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.6000</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>262.2500</td>\n",
       "      <td>7.7000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>526.5000</td>\n",
       "      <td>7.9000</td>\n",
       "      <td>78.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>777.7500</td>\n",
       "      <td>8.1000</td>\n",
       "      <td>86.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>997.0000</td>\n",
       "      <td>9.3000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  IMDB_Rating  Meta_score    Drama    Crime   Action  \\\n",
       "count    714.0000     714.0000    714.0000 714.0000 714.0000 714.0000   \n",
       "mean     518.5728       7.9371     77.1583   0.7003   0.1989   0.1961   \n",
       "std      295.8481       0.2933     12.4011   0.4585   0.3994   0.3973   \n",
       "min        0.0000       7.6000     28.0000   0.0000   0.0000   0.0000   \n",
       "25%      262.2500       7.7000     70.0000   0.0000   0.0000   0.0000   \n",
       "50%      526.5000       7.9000     78.0000   1.0000   0.0000   0.0000   \n",
       "75%      777.7500       8.1000     86.0000   1.0000   0.0000   0.0000   \n",
       "max      997.0000       9.3000    100.0000   1.0000   1.0000   1.0000   \n",
       "\n",
       "       Biography  Western   Comedy  Adventure  ...  Fantasy   Family  \\\n",
       "count   714.0000 714.0000 714.0000   714.0000  ... 714.0000 714.0000   \n",
       "mean      0.1232   0.0224   0.2255     0.2283  ...   0.0770   0.0602   \n",
       "std       0.3290   0.1481   0.4182     0.4200  ...   0.2668   0.2381   \n",
       "min       0.0000   0.0000   0.0000     0.0000  ...   0.0000   0.0000   \n",
       "25%       0.0000   0.0000   0.0000     0.0000  ...   0.0000   0.0000   \n",
       "50%       0.0000   0.0000   0.0000     0.0000  ...   0.0000   0.0000   \n",
       "75%       0.0000   0.0000   0.0000     0.0000  ...   0.0000   0.0000   \n",
       "max       1.0000   1.0000   1.0000     1.0000  ...   1.0000   1.0000   \n",
       "\n",
       "       Thriller  Romance   Sci-Fi      War    Music  Musical    Sport  History  \n",
       "count  714.0000 714.0000 714.0000 714.0000 714.0000 714.0000 714.0000 714.0000  \n",
       "mean     0.1387   0.1232   0.0784   0.0406   0.0490   0.0154   0.0238   0.0532  \n",
       "std      0.3458   0.3290   0.2690   0.1975   0.2161   0.1232   0.1526   0.2246  \n",
       "min      0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000  \n",
       "25%      0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000  \n",
       "50%      0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000  \n",
       "75%      0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000  \n",
       "max      1.0000   1.0000   1.0000   1.0000   1.0000   1.0000   1.0000   1.0000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8b524bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Released_Year'] = pd.to_numeric(df['Released_Year'], errors='coerce')\n",
    "df = df.dropna(subset=['Released_Year'])\n",
    "df['Released_Year'] = df['Released_Year'].astype(int)\n",
    "df['Gross'] = df['Gross'].str.replace(',', '').astype(int)\n",
    "df['Runtime'] = df['Runtime'].str.replace(' min', '').astype(int)\n",
    "df['Meta_score'] = df['Meta_score'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83194b48",
   "metadata": {},
   "source": [
    "**Columnas NO relevantes**\n",
    "- Series_Title → El nombre de la película no aporta directamente al rating.\n",
    "- IMDB_Rating → Es la variable objetivo, por lo que no se puede usar de predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a0e2f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Series_Title\",\"Director\"])\n",
    "X = df.drop(columns=[\"IMDB_Rating\"])\n",
    "y = df[\"IMDB_Rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f86c96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.get_dummies(X, columns=[\"Certificate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "42d778e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest=train_test_split(X,y,train_size=.4,random_state=137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6cc0ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(Xtrain)\n",
    "Xtrain_scaled = scaler.transform(Xtrain)\n",
    "Xtest_scaled  = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d3011f9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>IMDB_Rating</td>   <th>  R-squared:         </th> <td>   0.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.870</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   53.78</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 29 Sep 2025</td> <th>  Prob (F-statistic):</th> <td>3.24e-97</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:36:35</td>     <th>  Log-Likelihood:    </th> <td>  255.09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   285</td>      <th>  AIC:               </th> <td>  -436.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   248</td>      <th>  BIC:               </th> <td>  -301.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    36</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    7.9312</td> <td>    0.006</td> <td> 1263.355</td> <td> 0.000</td> <td>    7.919</td> <td>    7.944</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.2658</td> <td>    0.007</td> <td>  -36.635</td> <td> 0.000</td> <td>   -0.280</td> <td>   -0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0380</td> <td>    0.009</td> <td>   -4.187</td> <td> 0.000</td> <td>   -0.056</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0191</td> <td>    0.008</td> <td>    2.284</td> <td> 0.023</td> <td>    0.003</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0043</td> <td>    0.007</td> <td>    0.592</td> <td> 0.554</td> <td>   -0.010</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0107</td> <td>    0.008</td> <td>    1.285</td> <td> 0.200</td> <td>   -0.006</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0088</td> <td>    0.011</td> <td>    0.837</td> <td> 0.403</td> <td>   -0.012</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0001</td> <td>    0.008</td> <td>   -0.017</td> <td> 0.987</td> <td>   -0.016</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0002</td> <td>    0.009</td> <td>    0.022</td> <td> 0.982</td> <td>   -0.017</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0112</td> <td>    0.007</td> <td>   -1.500</td> <td> 0.135</td> <td>   -0.026</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0073</td> <td>    0.007</td> <td>   -1.051</td> <td> 0.294</td> <td>   -0.021</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.0065</td> <td>    0.008</td> <td>   -0.787</td> <td> 0.432</td> <td>   -0.023</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.0156</td> <td>    0.010</td> <td>   -1.542</td> <td> 0.124</td> <td>   -0.035</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.0072</td> <td>    0.009</td> <td>    0.812</td> <td> 0.417</td> <td>   -0.010</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.0059</td> <td>    0.008</td> <td>    0.745</td> <td> 0.457</td> <td>   -0.010</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.0071</td> <td>    0.007</td> <td>   -0.950</td> <td> 0.343</td> <td>   -0.022</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.0075</td> <td>    0.008</td> <td>   -0.928</td> <td> 0.354</td> <td>   -0.023</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   -0.0017</td> <td>    0.007</td> <td>   -0.229</td> <td> 0.819</td> <td>   -0.016</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.0068</td> <td>    0.007</td> <td>    0.914</td> <td> 0.362</td> <td>   -0.008</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.0094</td> <td>    0.008</td> <td>   -1.201</td> <td> 0.231</td> <td>   -0.025</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>   -0.0148</td> <td>    0.008</td> <td>   -1.971</td> <td> 0.050</td> <td>   -0.030</td> <td>-8.92e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>   -0.0006</td> <td>    0.008</td> <td>   -0.074</td> <td> 0.941</td> <td>   -0.016</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   -0.0063</td> <td>    0.007</td> <td>   -0.887</td> <td> 0.376</td> <td>   -0.020</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   -0.0045</td> <td>    0.008</td> <td>   -0.559</td> <td> 0.577</td> <td>   -0.020</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   -0.0055</td> <td>    0.009</td> <td>   -0.615</td> <td> 0.539</td> <td>   -0.023</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>   -0.0099</td> <td>    0.007</td> <td>   -1.394</td> <td> 0.165</td> <td>   -0.024</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>   -0.0050</td> <td>    0.007</td> <td>   -0.732</td> <td> 0.465</td> <td>   -0.019</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.0150</td> <td>    0.005</td> <td>    2.796</td> <td> 0.006</td> <td>    0.004</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>   -0.0068</td> <td>    0.008</td> <td>   -0.849</td> <td> 0.397</td> <td>   -0.023</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>   -0.0046</td> <td>    0.008</td> <td>   -0.562</td> <td> 0.575</td> <td>   -0.021</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.0067</td> <td>    0.007</td> <td>    0.960</td> <td> 0.338</td> <td>   -0.007</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.0028</td> <td>    0.007</td> <td>   -0.395</td> <td> 0.693</td> <td>   -0.017</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>    0.0003</td> <td>    0.006</td> <td>    0.051</td> <td> 0.960</td> <td>   -0.012</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -0.0125</td> <td>    0.008</td> <td>   -1.619</td> <td> 0.107</td> <td>   -0.028</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>   -0.0046</td> <td>    0.006</td> <td>   -0.784</td> <td> 0.434</td> <td>   -0.016</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>   -0.0040</td> <td>    0.006</td> <td>   -0.626</td> <td> 0.532</td> <td>   -0.017</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -0.0049</td> <td>    0.006</td> <td>   -0.772</td> <td> 0.441</td> <td>   -0.017</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.0006</td> <td>    0.006</td> <td>   -0.107</td> <td> 0.915</td> <td>   -0.013</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>257.881</td> <th>  Durbin-Watson:     </th> <td>   2.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>6449.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 3.612</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>25.157</td>  <th>  Cond. No.          </th> <td>1.46e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.26e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &   IMDB\\_Rating   & \\textbf{  R-squared:         } &     0.886   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.870   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     53.78   \\\\\n",
       "\\textbf{Date:}             & Mon, 29 Sep 2025 & \\textbf{  Prob (F-statistic):} &  3.24e-97   \\\\\n",
       "\\textbf{Time:}             &     21:36:35     & \\textbf{  Log-Likelihood:    } &    255.09   \\\\\n",
       "\\textbf{No. Observations:} &         285      & \\textbf{  AIC:               } &    -436.2   \\\\\n",
       "\\textbf{Df Residuals:}     &         248      & \\textbf{  BIC:               } &    -301.0   \\\\\n",
       "\\textbf{Df Model:}         &          36      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       7.9312  &        0.006     &  1263.355  &         0.000        &        7.919    &        7.944     \\\\\n",
       "\\textbf{x1}    &      -0.2658  &        0.007     &   -36.635  &         0.000        &       -0.280    &       -0.251     \\\\\n",
       "\\textbf{x2}    &      -0.0380  &        0.009     &    -4.187  &         0.000        &       -0.056    &       -0.020     \\\\\n",
       "\\textbf{x3}    &       0.0191  &        0.008     &     2.284  &         0.023        &        0.003    &        0.035     \\\\\n",
       "\\textbf{x4}    &       0.0043  &        0.007     &     0.592  &         0.554        &       -0.010    &        0.019     \\\\\n",
       "\\textbf{x5}    &       0.0107  &        0.008     &     1.285  &         0.200        &       -0.006    &        0.027     \\\\\n",
       "\\textbf{x6}    &       0.0088  &        0.011     &     0.837  &         0.403        &       -0.012    &        0.030     \\\\\n",
       "\\textbf{x7}    &      -0.0001  &        0.008     &    -0.017  &         0.987        &       -0.016    &        0.016     \\\\\n",
       "\\textbf{x8}    &       0.0002  &        0.009     &     0.022  &         0.982        &       -0.017    &        0.017     \\\\\n",
       "\\textbf{x9}    &      -0.0112  &        0.007     &    -1.500  &         0.135        &       -0.026    &        0.004     \\\\\n",
       "\\textbf{x10}   &      -0.0073  &        0.007     &    -1.051  &         0.294        &       -0.021    &        0.006     \\\\\n",
       "\\textbf{x11}   &      -0.0065  &        0.008     &    -0.787  &         0.432        &       -0.023    &        0.010     \\\\\n",
       "\\textbf{x12}   &      -0.0156  &        0.010     &    -1.542  &         0.124        &       -0.035    &        0.004     \\\\\n",
       "\\textbf{x13}   &       0.0072  &        0.009     &     0.812  &         0.417        &       -0.010    &        0.025     \\\\\n",
       "\\textbf{x14}   &       0.0059  &        0.008     &     0.745  &         0.457        &       -0.010    &        0.022     \\\\\n",
       "\\textbf{x15}   &      -0.0071  &        0.007     &    -0.950  &         0.343        &       -0.022    &        0.008     \\\\\n",
       "\\textbf{x16}   &      -0.0075  &        0.008     &    -0.928  &         0.354        &       -0.023    &        0.008     \\\\\n",
       "\\textbf{x17}   &      -0.0017  &        0.007     &    -0.229  &         0.819        &       -0.016    &        0.013     \\\\\n",
       "\\textbf{x18}   &       0.0068  &        0.007     &     0.914  &         0.362        &       -0.008    &        0.022     \\\\\n",
       "\\textbf{x19}   &      -0.0094  &        0.008     &    -1.201  &         0.231        &       -0.025    &        0.006     \\\\\n",
       "\\textbf{x20}   &      -0.0148  &        0.008     &    -1.971  &         0.050        &       -0.030    &    -8.92e-06     \\\\\n",
       "\\textbf{x21}   &      -0.0006  &        0.008     &    -0.074  &         0.941        &       -0.016    &        0.015     \\\\\n",
       "\\textbf{x22}   &      -0.0063  &        0.007     &    -0.887  &         0.376        &       -0.020    &        0.008     \\\\\n",
       "\\textbf{x23}   &      -0.0045  &        0.008     &    -0.559  &         0.577        &       -0.020    &        0.011     \\\\\n",
       "\\textbf{x24}   &      -0.0055  &        0.009     &    -0.615  &         0.539        &       -0.023    &        0.012     \\\\\n",
       "\\textbf{x25}   &      -0.0099  &        0.007     &    -1.394  &         0.165        &       -0.024    &        0.004     \\\\\n",
       "\\textbf{x26}   &      -0.0050  &        0.007     &    -0.732  &         0.465        &       -0.019    &        0.008     \\\\\n",
       "\\textbf{x27}   &       0.0150  &        0.005     &     2.796  &         0.006        &        0.004    &        0.026     \\\\\n",
       "\\textbf{x28}   &      -0.0068  &        0.008     &    -0.849  &         0.397        &       -0.023    &        0.009     \\\\\n",
       "\\textbf{x29}   &      -0.0046  &        0.008     &    -0.562  &         0.575        &       -0.021    &        0.011     \\\\\n",
       "\\textbf{x30}   &       0.0067  &        0.007     &     0.960  &         0.338        &       -0.007    &        0.020     \\\\\n",
       "\\textbf{x31}   &      -0.0028  &        0.007     &    -0.395  &         0.693        &       -0.017    &        0.011     \\\\\n",
       "\\textbf{x32}   &       0.0003  &        0.006     &     0.051  &         0.960        &       -0.012    &        0.013     \\\\\n",
       "\\textbf{x33}   &      -0.0125  &        0.008     &    -1.619  &         0.107        &       -0.028    &        0.003     \\\\\n",
       "\\textbf{x34}   &      -0.0046  &        0.006     &    -0.784  &         0.434        &       -0.016    &        0.007     \\\\\n",
       "\\textbf{x35}   &      -0.0040  &        0.006     &    -0.626  &         0.532        &       -0.017    &        0.009     \\\\\n",
       "\\textbf{x36}   &      -0.0049  &        0.006     &    -0.772  &         0.441        &       -0.017    &        0.008     \\\\\n",
       "\\textbf{x37}   &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{x38}   &      -0.0006  &        0.006     &    -0.107  &         0.915        &       -0.013    &        0.011     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 257.881 & \\textbf{  Durbin-Watson:     } &    2.129  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 6449.606  \\\\\n",
       "\\textbf{Skew:}          &   3.612 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  25.157 & \\textbf{  Cond. No.          } & 1.46e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 4.26e-30. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            IMDB_Rating   R-squared:                       0.886\n",
       "Model:                            OLS   Adj. R-squared:                  0.870\n",
       "Method:                 Least Squares   F-statistic:                     53.78\n",
       "Date:                Mon, 29 Sep 2025   Prob (F-statistic):           3.24e-97\n",
       "Time:                        21:36:35   Log-Likelihood:                 255.09\n",
       "No. Observations:                 285   AIC:                            -436.2\n",
       "Df Residuals:                     248   BIC:                            -301.0\n",
       "Df Model:                          36                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          7.9312      0.006   1263.355      0.000       7.919       7.944\n",
       "x1            -0.2658      0.007    -36.635      0.000      -0.280      -0.251\n",
       "x2            -0.0380      0.009     -4.187      0.000      -0.056      -0.020\n",
       "x3             0.0191      0.008      2.284      0.023       0.003       0.035\n",
       "x4             0.0043      0.007      0.592      0.554      -0.010       0.019\n",
       "x5             0.0107      0.008      1.285      0.200      -0.006       0.027\n",
       "x6             0.0088      0.011      0.837      0.403      -0.012       0.030\n",
       "x7            -0.0001      0.008     -0.017      0.987      -0.016       0.016\n",
       "x8             0.0002      0.009      0.022      0.982      -0.017       0.017\n",
       "x9            -0.0112      0.007     -1.500      0.135      -0.026       0.004\n",
       "x10           -0.0073      0.007     -1.051      0.294      -0.021       0.006\n",
       "x11           -0.0065      0.008     -0.787      0.432      -0.023       0.010\n",
       "x12           -0.0156      0.010     -1.542      0.124      -0.035       0.004\n",
       "x13            0.0072      0.009      0.812      0.417      -0.010       0.025\n",
       "x14            0.0059      0.008      0.745      0.457      -0.010       0.022\n",
       "x15           -0.0071      0.007     -0.950      0.343      -0.022       0.008\n",
       "x16           -0.0075      0.008     -0.928      0.354      -0.023       0.008\n",
       "x17           -0.0017      0.007     -0.229      0.819      -0.016       0.013\n",
       "x18            0.0068      0.007      0.914      0.362      -0.008       0.022\n",
       "x19           -0.0094      0.008     -1.201      0.231      -0.025       0.006\n",
       "x20           -0.0148      0.008     -1.971      0.050      -0.030   -8.92e-06\n",
       "x21           -0.0006      0.008     -0.074      0.941      -0.016       0.015\n",
       "x22           -0.0063      0.007     -0.887      0.376      -0.020       0.008\n",
       "x23           -0.0045      0.008     -0.559      0.577      -0.020       0.011\n",
       "x24           -0.0055      0.009     -0.615      0.539      -0.023       0.012\n",
       "x25           -0.0099      0.007     -1.394      0.165      -0.024       0.004\n",
       "x26           -0.0050      0.007     -0.732      0.465      -0.019       0.008\n",
       "x27            0.0150      0.005      2.796      0.006       0.004       0.026\n",
       "x28           -0.0068      0.008     -0.849      0.397      -0.023       0.009\n",
       "x29           -0.0046      0.008     -0.562      0.575      -0.021       0.011\n",
       "x30            0.0067      0.007      0.960      0.338      -0.007       0.020\n",
       "x31           -0.0028      0.007     -0.395      0.693      -0.017       0.011\n",
       "x32            0.0003      0.006      0.051      0.960      -0.012       0.013\n",
       "x33           -0.0125      0.008     -1.619      0.107      -0.028       0.003\n",
       "x34           -0.0046      0.006     -0.784      0.434      -0.016       0.007\n",
       "x35           -0.0040      0.006     -0.626      0.532      -0.017       0.009\n",
       "x36           -0.0049      0.006     -0.772      0.441      -0.017       0.008\n",
       "x37                 0          0        nan        nan           0           0\n",
       "x38           -0.0006      0.006     -0.107      0.915      -0.013       0.011\n",
       "==============================================================================\n",
       "Omnibus:                      257.881   Durbin-Watson:                   2.129\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6449.606\n",
       "Skew:                           3.612   Prob(JB):                         0.00\n",
       "Kurtosis:                      25.157   Cond. No.                     1.46e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 4.26e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ols=sm.add_constant(Xtrain_scaled)\n",
    "ols = sm.OLS(ytrain, X_ols)\n",
    "results = ols.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fe046958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train: 0.8864486792366304\n",
      "R2 test: 0.8967342420165834\n"
     ]
    }
   ],
   "source": [
    "Xtrain_scaled_const = sm.add_constant(Xtrain_scaled, has_constant=\"add\")\n",
    "Xtest_scaled_const  = sm.add_constant(Xtest_scaled, has_constant=\"add\")\n",
    "\n",
    "y_pred_train = results.predict(Xtrain_scaled_const)\n",
    "y_pred_test  = results.predict(Xtest_scaled_const)\n",
    "\n",
    "print(\"R2 train:\", r2_score(ytrain, y_pred_train))\n",
    "print(\"R2 test:\",  r2_score(ytest, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f519a17",
   "metadata": {},
   "source": [
    "1. Ajuste general del modelo\n",
    "\n",
    "El modelo tiene un R² = 0.886 y un Adj. R² = 0.870, lo que indica que explica una gran parte de la variabilidad de las calificaciones de IMDb. El desempeño en entrenamiento (R² = 0.886) y en prueba (R² = 0.897) es bastante consistente, lo que sugiere que el modelo generaliza bien y no hay un sobreajuste marcado.\n",
    "\n",
    "2. Variables con impacto significativo\n",
    "\n",
    "Las variables más relevantes (p < 0.05) son:\n",
    "\n",
    "Constante: 11.40, p < 0.001\n",
    "\n",
    "Años de lanzamiento (Released_Year): coef -0.0021, p < 0.001 → películas más recientes ligeramente peor calificadas.\n",
    "\n",
    "Runtime: coef 0.0007, p = 0.023 → películas más largas tienden a tener un puntaje ligeramente mayor.\n",
    "\n",
    "Certificados (ratings): Certificate_A, Approved, G, GP, PG, PG-13, Passed, R, TV-PG, U, UA → todos significativos, coeficientes positivos ~0.93 a 1.17, lo que indica que ciertos ratings se asocian con calificaciones más altas.\n",
    "\n",
    "3. Variables poco o nada significativas\n",
    "\n",
    "La mayoría de los géneros (Drama, Crime, Action, Adventure, Horror, Sci-Fi, etc.) no son significativos, lo que indica que el género de la película no tiene un efecto fuerte en las calificaciones.\n",
    "\n",
    "Gross y Meta_score tampoco son significativos, por lo que la recaudación o la puntuación crítica no influyen notablemente en este modelo.\n",
    "\n",
    "4. Posibles problemas\n",
    "\n",
    "Muchísimas variables dummies de directores y géneros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a12a7b",
   "metadata": {},
   "source": [
    "## P-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "084acfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression()\n",
    "lr.fit(Xtrain_scaled,ytrain)\n",
    "\n",
    "y_pred = lr.predict(Xtrain_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b562d07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados OLS (todas las variables):\n",
      "                Variable             Coef  Std_Error            t_value  \\\n",
      "0             Intercepto           7.9312     0.0063          1258.2547   \n",
      "1             Unnamed: 0          -0.2658     0.0073           -36.4873   \n",
      "2          Released_Year          -0.0380     0.0091            -4.1698   \n",
      "3                Runtime           0.0191     0.0084             2.2761   \n",
      "4             Meta_score           0.0043     0.0073             0.5906   \n",
      "5                  Gross           0.0107     0.0084             1.2802   \n",
      "6                  Drama           0.0088     0.0106             0.8326   \n",
      "7                  Crime          -0.0001     0.0080            -0.0165   \n",
      "8                 Action           0.0002     0.0086             0.0223   \n",
      "9              Biography          -0.0112     0.0075            -1.4937   \n",
      "10               Western          -0.0073     0.0070            -1.0467   \n",
      "11                Comedy          -0.0065     0.0083            -0.7824   \n",
      "12             Adventure          -0.0156     0.0101            -1.5367   \n",
      "13             Animation           0.0072     0.0089             0.8084   \n",
      "14                Horror           0.0059     0.0080             0.7441   \n",
      "15               Mystery          -0.0071     0.0075            -0.9495   \n",
      "16             Film-Noir          -0.0075     0.0081            -0.9240   \n",
      "17               Fantasy          -0.0017     0.0073            -0.2282   \n",
      "18                Family           0.0068     0.0075             0.9106   \n",
      "19              Thriller          -0.0094     0.0078            -1.1968   \n",
      "20               Romance          -0.0148     0.0075            -1.9643   \n",
      "21                Sci-Fi          -0.0006     0.0078            -0.0742   \n",
      "22                   War          -0.0063     0.0072            -0.8832   \n",
      "23                 Music          -0.0045     0.0080            -0.5562   \n",
      "24               Musical          -0.0055     0.0090            -0.6120   \n",
      "25                 Sport          -0.0099     0.0072            -1.3888   \n",
      "26               History          -0.0050     0.0069            -0.7286   \n",
      "27         Certificate_A 28597236056.4789     0.0054 5307108134491.0029   \n",
      "28  Certificate_Approved  6599777626.1017     0.0081  819156448887.3243   \n",
      "29         Certificate_G  5398241836.6415     0.0081  663603765954.6981   \n",
      "30        Certificate_GP  3823871514.0033     0.0070  544899570019.8240   \n",
      "31        Certificate_PG 10009572719.1899     0.0072 1392241696324.3298   \n",
      "32     Certificate_PG-13 15315669244.0797     0.0064 2389176284635.3799   \n",
      "33    Certificate_Passed  6599777626.0959     0.0078  849109220487.0818   \n",
      "34         Certificate_R 25520512044.7673     0.0059 4339384882612.0737   \n",
      "35     Certificate_TV-PG  3823871513.9926     0.0065  590102215018.1855   \n",
      "36         Certificate_U 26680403747.5670     0.0063 4224239400457.2407   \n",
      "37       Certificate_U/A           0.0000     0.0000                NaN   \n",
      "38        Certificate_UA 26035807176.8358     0.0060 4304695490698.1313   \n",
      "\n",
      "    p_value  \n",
      "0    0.0000  \n",
      "1    0.0000  \n",
      "2    0.0000  \n",
      "3    0.0237  \n",
      "4    0.5553  \n",
      "5    0.2017  \n",
      "6    0.4059  \n",
      "7    0.9868  \n",
      "8    0.9822  \n",
      "9    0.1365  \n",
      "10   0.2963  \n",
      "11   0.4347  \n",
      "12   0.1257  \n",
      "13   0.4197  \n",
      "14   0.4575  \n",
      "15   0.3433  \n",
      "16   0.3564  \n",
      "17   0.8197  \n",
      "18   0.3634  \n",
      "19   0.2326  \n",
      "20   0.0506  \n",
      "21   0.9409  \n",
      "22   0.3780  \n",
      "23   0.5786  \n",
      "24   0.5411  \n",
      "25   0.1662  \n",
      "26   0.4669  \n",
      "27   0.0000  \n",
      "28   0.0000  \n",
      "29   0.0000  \n",
      "30   0.0000  \n",
      "31   0.0000  \n",
      "32   0.0000  \n",
      "33   0.0000  \n",
      "34   0.0000  \n",
      "35   0.0000  \n",
      "36   0.0000  \n",
      "37      NaN  \n",
      "38   0.0000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michelle Trigo\\AppData\\Local\\Temp\\ipykernel_6136\\1416078757.py:29: RuntimeWarning: invalid value encountered in divide\n",
      "  t_stats = coefs / std_beta\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Ajuste del modelo\n",
    "lr = LinearRegression()\n",
    "lr.fit(Xtrain_scaled, ytrain)\n",
    "\n",
    "# Predicciones en train\n",
    "y_hat = lr.predict(Xtrain_scaled)\n",
    "\n",
    "# Diseño con constante\n",
    "X_design = np.column_stack([np.ones(Xtrain_scaled.shape[0]), Xtrain_scaled])\n",
    "\n",
    "# Residual sum of squares y residual standard error\n",
    "rss = np.sum((ytrain - y_hat) ** 2)\n",
    "n, k = Xtrain_scaled.shape\n",
    "rse = np.sqrt(rss / (n - k - 1))\n",
    "\n",
    "# Varianzas usando pseudo-inversa en lugar de inversa\n",
    "var_beta = np.linalg.pinv(X_design.T @ X_design) * rse**2\n",
    "std_beta = np.sqrt(np.diag(var_beta))\n",
    "\n",
    "# Coeficientes (intercepto + betas)\n",
    "coefs = np.insert(lr.coef_, 0, lr.intercept_)\n",
    "\n",
    "# Estadísticos t y p-values\n",
    "t_stats = coefs / std_beta\n",
    "p_values = [2 * (1 - stats.t.cdf(np.abs(t), df=n - k - 1)) for t in t_stats]\n",
    "\n",
    "# Resultados en un DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"Variable\": [\"Intercepto\"] + list(X.columns),\n",
    "    \"Coef\": coefs,\n",
    "    \"Std_Error\": std_beta,\n",
    "    \"t_value\": t_stats,\n",
    "    \"p_value\": p_values\n",
    "})\n",
    "\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:.4f}\")\n",
    "print(\"\\nResultados OLS (todas las variables):\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b090fc6",
   "metadata": {},
   "source": [
    "1. \n",
    "**¿Cuál fue el error?**\n",
    "Eliminé la columna de Unnamed 0\n",
    "**¿Cuál es la corrección?**\n",
    "La incluí en la regresión\n",
    "**¿Por qué se cometió el error?**\n",
    "Pensé que no tenía impacto.\n",
    "**¿Cómo se puede evitar este error en el futuro? (Métodos prácticos aplicables. Nada de “estudiar más”)**\n",
    "Hacer pruebas y analizar el P-value de todas las variables antes de eliminar alguna.\n",
    " \n",
    "2.  \n",
    "**¿Cuál fue el error?**\n",
    "Eliminé la columna de Gross\n",
    "**¿Cuál es la corrección?**\n",
    "Modifiqué el df para eliminar las comas de los valores y los pudiera convertir a int.\n",
    "**¿Por qué se cometió el error?**\n",
    "No recordé como hacerlo en el momento.\n",
    "**¿Cómo se puede evitar este error en el futuro? (Métodos prácticos aplicables. Nada de “estudiar más”)**\n",
    "Recordar técnicas de manipulación de datos básicos, llendo a asesorías o haciendo las prácticas de las asesorías enfocadas en eso.\n",
    "\n",
    "3.\n",
    "**¿Cuál fue el error?**\n",
    "Eliminé la columna de Runtime.\n",
    "**¿Cuál es la corrección?**\n",
    "Modifiqué el df para quitarle el \"min\" de los valores para poder convertirlos a int.\n",
    "**¿Por qué se cometió el error?**\n",
    "No recordé como hacerlo en el momento.\n",
    "**¿Cómo se puede evitar este error en el futuro? (Métodos prácticos aplicables. Nada de “estudiar más”)**\n",
    "Recordar técnicas de manipulación de datos básicos, llendo a asesorías o haciendo las prácticas de las asesorías enfocadas en eso.\n",
    "\n",
    "4.\n",
    "**¿Cuál fue el error?**\n",
    "Eliminé la columna de Runtime.\n",
    "**¿Cuál es la corrección?**\n",
    "Modifiqué el df para quitarle el \"min\" de los valores para poder convertirlos a int.\n",
    "**¿Por qué se cometió el error?**\n",
    "No recordé como hacerlo en el momento.\n",
    "**¿Cómo se puede evitar este error en el futuro? (Métodos prácticos aplicables. Nada de “estudiar más”)**\n",
    "Recordar técnicas de manipulación de datos básicos, llendo a asesorías o haciendo las prácticas de las asesorías enfocadas en eso.\n",
    "\n",
    "5. \n",
    "**¿Cuál fue el error?**\n",
    "No haber borrado la columna de \"Director\"\n",
    "**¿Cuál es la corrección?**\n",
    "Eliminarla antes de hacer la regresión\n",
    "**¿Por qué se cometió el error?**\n",
    "No me di cuenta que la mayoría de los directores solo hicieron una película, lo que hace que esta información sea muy específica de cada caso y no generalice bien. Mantenerla causaba que el modelo se sobreajustara a los datos de entrenamiento y fallara al predecir nuevas películas.\n",
    "**¿Cómo se puede evitar este error en el futuro?** \n",
    "En este caso, me hizo falta más tiempo para hacer más pruebas y notar ese punto antes.\n",
    "\n",
    "6.\n",
    "**¿Cuál fue el error?**\n",
    "No haber calculado los p-values a mano.\n",
    "**¿Cuál es la corrección?**\n",
    "Calcularlos.\n",
    "**¿Por qué se cometió el error?**\n",
    "No me dio suficiente tiempo para hacerlo, aparte no tenía preparado el código para hacerlo.\n",
    "**¿Cómo se puede evitar este error en el futuro?** \n",
    "En este caso, me hizo falta más tiempo, pero hubiera servido tener los códigos preparados desde antes.\n",
    "\n",
    "7.\n",
    "**¿Cuál fue el error?**\n",
    "Interpretación de resultados\n",
    "**¿Cuál es la corrección?**\n",
    "Nueva interpretación con los nuevos resultados.\n",
    "**¿Por qué se cometió el error?**\n",
    "Interpreté los resultados que tenía, que eran erróneos.\n",
    "**¿Cómo se puede evitar este error en el futuro?** \n",
    "No equivocarme con los resultados para interpretar los correctos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a40bc39",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a189894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
